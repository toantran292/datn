\subsection{Giới thiệu về Large Language Models (LLM)}

\subsubsection{Khái quát}

Large Language Models (LLM) là các mô hình AI được train trên lượng lớn text data, có khả năng hiểu và sinh ra ngôn ngữ tự nhiên một cách linh hoạt và chính xác. LLMs sử dụng kiến trúc Transformer với hàng tỷ parameters để học patterns phức tạp trong ngôn ngữ, từ cú pháp đơn giản đến semantic understanding và reasoning ở mức cao. Khác với các mô hình AI truyền thống chỉ thực hiện một task cụ thể, LLMs có khả năng generative sinh ra text mới, few-shot và zero-shot learning thực hiện tasks mới với ít hoặc không có examples, context understanding hiểu ngữ cảnh của đoạn hội thoại dài, và multi-task capabilities thực hiện nhiều loại tasks khác nhau như summarization, translation, question answering, và code generation.

\subsubsection{LLM Providers và đặc điểm}

Thị trường LLM hiện nay có ba providers chính cung cấp các models với đặc điểm khác nhau. OpenAI GPT-4 là model mạnh mẽ nhất của OpenAI với khả năng reasoning và creative tasks xuất sắc, hỗ trợ 128K token context window, có phiên bản GPT-4 Turbo với giá rẻ hơn và GPT-4 Vision hỗ trợ image input. Anthropic Claude được thiết kế với focus vào safety và helpfulness, Claude 3 có context window lên đến 200K tokens cho phép xử lý documents dài, với các phiên bản Opus (mạnh nhất), Sonnet (cân bằng giữa performance và cost), và Haiku (nhanh và rẻ cho tasks đơn giản). Google Gemini là model multimodal có thể xử lý text, images, audio, và video, tích hợp sâu với Google ecosystem, với các phiên bản Ultra, Pro, và Nano phù hợp cho các use cases khác nhau từ enterprise đến on-device applications.

\subsubsection{Kỹ thuật Prompt Engineering}

Prompt Engineering là nghệ thuật và khoa học của việc thiết kế prompts hiệu quả để có được kết quả mong muốn từ LLMs. Các kỹ thuật chính bao gồm Zero-shot Prompting yêu cầu model thực hiện task mà không có examples trước, Few-shot Prompting cung cấp một vài examples để model học pattern và áp dụng cho task chính, Chain-of-Thought (CoT) prompting yêu cầu model giải thích reasoning từng bước để cải thiện accuracy cho complex tasks, System Prompts định nghĩa persona và constraints cho model tạo ra consistent behavior, và Structured Output prompting yêu cầu model trả về format cụ thể như JSON hoặc XML để dễ dàng parse và integrate vào applications. Việc áp dụng đúng kỹ thuật prompt engineering có thể cải thiện đáng kể chất lượng output và giảm hallucinations của LLMs.

\subsubsection{LangChain.js Framework}

LangChain.js là JavaScript/TypeScript implementation của LangChain framework, được thiết kế để tích hợp LLMs vào Node.js applications một cách có cấu trúc và dễ bảo trì. Framework này cung cấp abstraction layer cho Chains kết hợp nhiều LLM calls hoặc tools theo sequence, Agents cho phép LLM tự quyết định tools nào cần sử dụng để hoàn thành task, Memory lưu trữ conversation history để maintain context qua nhiều interactions, Structured Output parsing với Zod schemas để extract typed data từ LLM responses, support cho multiple providers (OpenAI, Anthropic, Google, và nhiều providers khác) với unified interface, và Streaming capabilities để stream responses real-time cải thiện user experience. LangChain.js giúp developers xây dựng LLM-powered applications một cách nhanh chóng và reliable.

\subsubsection{Vận dụng vào đề tài}

PM Service được xây dựng bằng NestJS tích hợp LLM thông qua AIModule để cung cấp các tính năng AI hỗ trợ quản lý dự án. Service hỗ trợ multi-provider configuration cho phép organization chọn giữa OpenAI GPT-4 và Anthropic Claude dựa trên nhu cầu và budget, với khả năng switch provider linh hoạt thông qua organization settings. LangChain.js được sử dụng để orchestrate LLM calls với chains, quản lý prompts và extract structured data từ LLM responses với type-safe parsing bằng Zod schemas.

AIModule cung cấp ba tính năng AI chính cho PM subsystem. AI Sprint Summary tự động tổng hợp sprint khi Project Lead complete sprint, collect dữ liệu từ completed issues, remaining issues, và sprint activities, format prompt với sprint context (tên sprint, mục tiêu, timeline, velocity), call LLM API để generate summary với structured format JSON bao gồm các sections (Overview, Achievements, Issues Found, Recommendations), và lưu summary vào Sprint entity để hiển thị trong sprint retrospective. AI Issue Description Generation hỗ trợ users khi tạo issue mới, nhận issue title từ user input, tạo prompt với project context và issue type (STORY, TASK, BUG, EPIC), call LLM để generate detailed description với acceptance criteria và technical notes, hiển thị suggested description trong editor để user có thể edit trước khi save. AI Task Breakdown giúp decompose EPIC hoặc STORY thành sub-tasks, analyze issue description và requirements, suggest danh sách sub-tasks với titles, descriptions, và estimated story points, users có thể select và adjust suggested tasks trước khi create sub-issues.

Streaming response được implement cho AI Sprint Summary để cải thiện UX khi generate summary dài, cho phép Project Lead thấy output real-time thay vì chờ đợi toàn bộ response. System track tokens consumed và cost estimation cho mỗi AI request, implement retry logic với exponential backoff cho LLM API failures, và cache prompts templates để optimize performance. Error handling đảm bảo AI features là optional enhancements không block core PM operations.
