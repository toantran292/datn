\subsection{Giới thiệu về Large Language Models (LLM)}

\subsubsection{Khái quát}

Large Language Models (LLM) là các mô hình AI được train trên lượng lớn text data, có khả năng hiểu và sinh ra ngôn ngữ tự nhiên một cách linh hoạt và chính xác. LLMs sử dụng kiến trúc Transformer với hàng tỷ parameters để học patterns phức tạp trong ngôn ngữ, từ cú pháp đơn giản đến semantic understanding và reasoning ở mức cao. Khác với các mô hình AI truyền thống chỉ thực hiện một task cụ thể, LLMs có khả năng generative sinh ra text mới, few-shot và zero-shot learning thực hiện tasks mới với ít hoặc không có examples, context understanding hiểu ngữ cảnh của đoạn hội thoại dài, và multi-task capabilities thực hiện nhiều loại tasks khác nhau như summarization, translation, question answering, và code generation.

\subsubsection{LLM Providers và đặc điểm}

Thị trường LLM hiện nay có ba providers chính cung cấp các models với đặc điểm khác nhau. OpenAI GPT-4 là model mạnh mẽ nhất của OpenAI với khả năng reasoning và creative tasks xuất sắc, hỗ trợ 128K token context window, có phiên bản GPT-4 Turbo với giá rẻ hơn và GPT-4 Vision hỗ trợ image input. Anthropic Claude được thiết kế với focus vào safety và helpfulness, Claude 3 có context window lên đến 200K tokens cho phép xử lý documents dài, với các phiên bản Opus (mạnh nhất), Sonnet (cân bằng giữa performance và cost), và Haiku (nhanh và rẻ cho tasks đơn giản). Google Gemini là model multimodal có thể xử lý text, images, audio, và video, tích hợp sâu với Google ecosystem, với các phiên bản Ultra, Pro, và Nano phù hợp cho các use cases khác nhau từ enterprise đến on-device applications.

\subsubsection{Kỹ thuật Prompt Engineering}

Prompt Engineering là nghệ thuật và khoa học của việc thiết kế prompts hiệu quả để có được kết quả mong muốn từ LLMs. Các kỹ thuật chính bao gồm Zero-shot Prompting yêu cầu model thực hiện task mà không có examples trước, Few-shot Prompting cung cấp một vài examples để model học pattern và áp dụng cho task chính, Chain-of-Thought (CoT) prompting yêu cầu model giải thích reasoning từng bước để cải thiện accuracy cho complex tasks, System Prompts định nghĩa persona và constraints cho model tạo ra consistent behavior, và Structured Output prompting yêu cầu model trả về format cụ thể như JSON hoặc XML để dễ dàng parse và integrate vào applications. Việc áp dụng đúng kỹ thuật prompt engineering có thể cải thiện đáng kể chất lượng output và giảm hallucinations của LLMs.

\subsubsection{LangChain.js Framework}

LangChain.js là JavaScript/TypeScript implementation của LangChain framework, được thiết kế để tích hợp LLMs vào Node.js applications một cách có cấu trúc và dễ bảo trì. Framework này cung cấp abstraction layer cho Chains kết hợp nhiều LLM calls hoặc tools theo sequence, Agents cho phép LLM tự quyết định tools nào cần sử dụng để hoàn thành task, Memory lưu trữ conversation history để maintain context qua nhiều interactions, Structured Output parsing với Zod schemas để extract typed data từ LLM responses, support cho multiple providers (OpenAI, Anthropic, Google, và nhiều providers khác) với unified interface, và Streaming capabilities để stream responses real-time cải thiện user experience. LangChain.js giúp developers xây dựng LLM-powered applications một cách nhanh chóng và reliable.

\subsubsection{Vận dụng vào đề tài}

Report Service được xây dựng bằng NestJS tích hợp LLM để tạo báo cáo AI tổng hợp từ dữ liệu workspace. Service hỗ trợ multi-provider configuration cho phép workspace owner chọn giữa OpenAI GPT-4, Anthropic Claude, hoặc Google Gemini dựa trên nhu cầu và budget, với khả năng switch provider linh hoạt thông qua workspace settings. LangChain.js được sử dụng để orchestrate LLM calls với chains, quản lý conversation memory cho context-aware responses khi generate báo cáo dài, và extract structured data từ LLM responses với type-safe parsing.

Chức năng report generation sử dụng LLM để tổng hợp dữ liệu từ nhiều nguồn như files, activities, và workspace metadata thành báo cáo có insights và recommendations. Workspace owner có thể tạo custom prompt templates cho các loại báo cáo khác nhau (weekly summary, project analysis, performance review), mỗi template được lưu trong database và có thể reuse. LLM trả về structured JSON format với sections, key findings, và actionable items, giúp hiển thị báo cáo có cấu trúc rõ ràng trên frontend. Streaming response được implement để cải thiện UX khi generate báo cáo dài, cho phép users thấy output real-time thay vì chờ đợi toàn bộ response. System cũng track tokens consumed và cost estimation cho mỗi report generation request.
